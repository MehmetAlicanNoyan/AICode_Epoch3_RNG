{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Wikipedia\n",
    "https://en.wikipedia.org/wiki/Linear_congruential_generator\n",
    "\n",
    "A linear congruential generator (LCG) is an algorithm that yields a sequence of pseudo-randomized numbers calculated with a discontinuous piecewise linear equation. The method represents one of the oldest and best-known pseudorandom number generator algorithms. The theory behind them is relatively easy to understand, and they are easily implemented and fast, especially on computer hardware which can provide modulo arithmetic by storage-bit truncation.\n",
    "\n",
    "The generator is defined by recurrence relation:\n",
    "\n",
    "\\begin{align}\n",
    "X_{n+1} = (aX_{n} + c)\\:mod\\:m\n",
    "\\end{align}\n",
    "\n",
    "where X is the sequence of pseudorandom values, and\n",
    "\n",
    "\\begin{align}\n",
    "m, 0<m - the\\:modulus \\\\\n",
    "a, 0<a<m - the\\:multiplier \\\\\n",
    "c, 0 \\leqslant c<m - the\\:increment \\\\\n",
    "X_{0}, 0 \\leqslant X_{0} < m - the\\:seed\n",
    "\\end{align}\n",
    "\n",
    "are integer constants that specify the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def int_to_bin_seq(x, num_digit):\n",
    "    '''\n",
    "    converts integer to binary sequence list\n",
    "    of specified length by num_digit\n",
    "    \n",
    "    e.g. x=4, num_digit=3  to [1,0,0]\n",
    "    e.g. x=4, num_digit=4  to [0,1,0,0]\n",
    "    '''\n",
    "    # convert int to binary string\n",
    "    # e.g. 4 to '100'\n",
    "    x_bin = '{0:b}'.format(x)\n",
    "    # convert binary string to sequence of integers\n",
    "    # e.g. '100' to [1, 0 ,0]\n",
    "    x_bin_seq = list(map(int,x_bin))\n",
    "    \n",
    "    # add zeros in front if needed\n",
    "    x_bin_seq = [0]*(num_digit-len(x_bin_seq)) + x_bin_seq\n",
    "    \n",
    "    return x_bin_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcg_generator(m, a, c, seq_len, seed = 'random'):\n",
    "    '''\n",
    "    For a given m and coeffs a and c,\n",
    "    generates binary numbers of length (seq_len),\n",
    "    based on linear congruential generator algorithm.\n",
    "    '''\n",
    "    # calculate the num of binary digits\n",
    "    # necessary to represent nums.\n",
    "    num_digit = int(np.ceil(np.log2(m)))\n",
    "    \n",
    "    # generate random seed\n",
    "    if seed == 'random':\n",
    "        x_init = np.random.randint(0,m)\n",
    "    else:\n",
    "        x_init = seed\n",
    "\n",
    "    # convert int to binary sequence\n",
    "    x_init_bin_seq = int_to_bin_seq(x_init, num_digit)\n",
    "\n",
    "    # initialize sequence\n",
    "    sequence = []\n",
    "    sequence += x_init_bin_seq\n",
    "\n",
    "    # initialize recurrence relation\n",
    "    x = x_init\n",
    "    \n",
    "    while len(sequence) < seq_len:\n",
    "        # recurrence relation\n",
    "        x_next = (a*x + c) % m\n",
    "        # convert int to binary sequence\n",
    "        x_next_bin_seq = int_to_bin_seq(x_next, num_digit)\n",
    "        # add this to sequence\n",
    "        sequence += x_next_bin_seq\n",
    "        # prepare for the following loop\n",
    "        x = x_next\n",
    "        \n",
    "    # crop to fixed size    \n",
    "    sequence = sequence[0:seq_len]\n",
    "    \n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNs_training = lcg_generator(m=15, a=5, c=10, seq_len=2000, seed = 'random')\n",
    "RNs_test = lcg_generator(m=15, a=5, c=10, seq_len=500, seed = 'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generator(RNs, inp_seq_len, step):\n",
    "    X = []\n",
    "    y = []\n",
    "    i = 0\n",
    "    while i+inp_seq_len+1<=len(RNs):\n",
    "        X.append(RNs[i:i+inp_seq_len])\n",
    "        y.append(RNs[i+inp_seq_len])\n",
    "        i+=step\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_seq_len = 50\n",
    "X_train, y_train = dataset_generator(RNs_training, inp_seq_len, step=1)\n",
    "X_test, y_test = dataset_generator(RNs_test, inp_seq_len, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,461\n",
      "Trainable params: 1,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=inp_seq_len, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1950 samples, validate on 450 samples\n",
      "Epoch 1/5\n",
      "1950/1950 [==============================] - 0s 179us/step - loss: 0.1556 - acc: 0.8128 - val_loss: 0.0429 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "1950/1950 [==============================] - 0s 52us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "1950/1950 [==============================] - 0s 55us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 9.1690e-04 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "1950/1950 [==============================] - 0s 67us/step - loss: 5.4251e-04 - acc: 1.0000 - val_loss: 3.4289e-04 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "1950/1950 [==============================] - 0s 80us/step - loss: 2.6720e-04 - acc: 1.0000 - val_loss: 2.0795e-04 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"JRNG.txt\", \"r\") # open\n",
    "JRNG = list(f.read()) # read\n",
    "JRNG = list(map(int, JRNG)) # convert to integers\n",
    "JRNG = np.array(JRNG) # convert list to np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if it is only 0's and 1's\n",
    "np.unique(JRNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete non-0's and non-1's\n",
    "JRNG = JRNG[JRNG != 2]\n",
    "JRNG = JRNG[JRNG != 4]\n",
    "np.unique(JRNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_seq_len = 50\n",
    "X_train, y_train = dataset_generator(JRNG[0:1500], inp_seq_len, step=1)\n",
    "X_test, y_test = dataset_generator(JRNG[1500:], inp_seq_len, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,461\n",
      "Trainable params: 1,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=inp_seq_len, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1450 samples, validate on 446 samples\n",
      "Epoch 1/20\n",
      "1450/1450 [==============================] - 0s 235us/step - loss: 0.2394 - acc: 0.5910 - val_loss: 0.2375 - val_acc: 0.5740\n",
      "Epoch 2/20\n",
      "1450/1450 [==============================] - 0s 56us/step - loss: 0.2173 - acc: 0.6876 - val_loss: 0.2188 - val_acc: 0.6659\n",
      "Epoch 3/20\n",
      "1450/1450 [==============================] - 0s 76us/step - loss: 0.1977 - acc: 0.7297 - val_loss: 0.1988 - val_acc: 0.7063\n",
      "Epoch 4/20\n",
      "1450/1450 [==============================] - 0s 82us/step - loss: 0.1826 - acc: 0.7393 - val_loss: 0.1815 - val_acc: 0.7489\n",
      "Epoch 5/20\n",
      "1450/1450 [==============================] - 0s 60us/step - loss: 0.1719 - acc: 0.7510 - val_loss: 0.1665 - val_acc: 0.7825\n",
      "Epoch 6/20\n",
      "1450/1450 [==============================] - 0s 92us/step - loss: 0.1667 - acc: 0.7634 - val_loss: 0.1587 - val_acc: 0.7937\n",
      "Epoch 7/20\n",
      "1450/1450 [==============================] - 0s 92us/step - loss: 0.1604 - acc: 0.7697 - val_loss: 0.1567 - val_acc: 0.7982\n",
      "Epoch 8/20\n",
      "1450/1450 [==============================] - 0s 79us/step - loss: 0.1573 - acc: 0.7772 - val_loss: 0.1536 - val_acc: 0.8117\n",
      "Epoch 9/20\n",
      "1450/1450 [==============================] - 0s 69us/step - loss: 0.1564 - acc: 0.7793 - val_loss: 0.1496 - val_acc: 0.7982\n",
      "Epoch 10/20\n",
      "1450/1450 [==============================] - 0s 80us/step - loss: 0.1531 - acc: 0.7807 - val_loss: 0.1489 - val_acc: 0.8139\n",
      "Epoch 11/20\n",
      "1450/1450 [==============================] - 0s 110us/step - loss: 0.1506 - acc: 0.7903 - val_loss: 0.1500 - val_acc: 0.8072\n",
      "Epoch 12/20\n",
      "1450/1450 [==============================] - 0s 88us/step - loss: 0.1489 - acc: 0.7869 - val_loss: 0.1494 - val_acc: 0.8094\n",
      "Epoch 13/20\n",
      "1450/1450 [==============================] - 0s 59us/step - loss: 0.1483 - acc: 0.7945 - val_loss: 0.1479 - val_acc: 0.8049\n",
      "Epoch 14/20\n",
      "1450/1450 [==============================] - 0s 71us/step - loss: 0.1466 - acc: 0.7959 - val_loss: 0.1493 - val_acc: 0.8184\n",
      "Epoch 15/20\n",
      "1450/1450 [==============================] - 0s 73us/step - loss: 0.1444 - acc: 0.8041 - val_loss: 0.1494 - val_acc: 0.8117\n",
      "Epoch 16/20\n",
      "1450/1450 [==============================] - 0s 68us/step - loss: 0.1430 - acc: 0.8014 - val_loss: 0.1501 - val_acc: 0.8184\n",
      "Epoch 17/20\n",
      "1450/1450 [==============================] - 0s 94us/step - loss: 0.1403 - acc: 0.8041 - val_loss: 0.1489 - val_acc: 0.8139\n",
      "Epoch 18/20\n",
      "1450/1450 [==============================] - 0s 85us/step - loss: 0.1400 - acc: 0.8097 - val_loss: 0.1503 - val_acc: 0.8139\n",
      "Epoch 19/20\n",
      "1450/1450 [==============================] - 0s 105us/step - loss: 0.1375 - acc: 0.8138 - val_loss: 0.1498 - val_acc: 0.8184\n",
      "Epoch 20/20\n",
      "1450/1450 [==============================] - 0s 96us/step - loss: 0.1371 - acc: 0.8138 - val_loss: 0.1509 - val_acc: 0.8117\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
